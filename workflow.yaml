jobs:
  - pysparkJob:
      args:
      - 'g1'
      - 'com.globo.g1.app'
      - 'batch'
      mainPythonFileUri: file:///pipeline/src/deea/jobs/ingestor.py
    stepId: ingestor
placement:
  managedCluster:
    clusterName: deeapipeline
    config:
      gceClusterConfig:
        zoneUri: us-east1-b
        serviceAccountScopes:
        - https://www.googleapis.com/auth/cloud-platform
        - https://www.googleapis.com/auth/cloud.useraccounts.readonly
        - https://www.googleapis.com/auth/devstorage.read_write
        - https://www.googleapis.com/auth/logging.write
      softwareConfig:
        properties:
          spark:spark.executor.memory: 4gb
          spark:spark.driver.maxResultSize: 4gb
          dataproc:jobs.file-backed-output.enable: 'true'
          dataproc:dataproc.logging.stackdriver.enable: 'true'
          dataproc:dataproc.monitoring.stackdriver.enable: 'true'
      initializationActions:
      - executableFile: gs://krtn/pipeline/scripts/init.sh
      masterConfig:
        machineTypeUri: n1-standard-2
      workerConfig:
        machineTypeUri: n1-standard-2
        numInstances: 2
      secondaryWorkerConfig:
        machineTypeUri: n1-standard-2
        numInstances: 2
        isPreemptible: true
